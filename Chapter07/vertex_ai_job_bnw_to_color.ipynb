{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b80af36d-be92-44bb-b84f-e7de7d7a038c",
   "metadata": {},
   "source": [
    "# Convert Black-n-White image to Color Images - Vertex AI Training Job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3568b64-9299-4eb8-a99d-3b7c6ddda61b",
   "metadata": {},
   "source": [
    "### Dependencies\n",
    "\n",
    "#### Before running this notebook, please make sure you have already installed the following libraries with correct versions.\n",
    "\n",
    "- numpy==1.21.6\n",
    "- google-cloud-aiplatform==1.24.1\n",
    "- google-cloud-storage==2.9.0\n",
    "- pillow==9.5.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cdd52bf-29ab-4851-9b21-ff0ad7814b84",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7e93550-5b0d-4558-9cd8-6c5fb7465f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from google.cloud import aiplatform\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61787ad8-d88a-4129-b521-7456074c6a49",
   "metadata": {},
   "source": [
    "## Setup project configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c80379c-99e9-495e-89bf-d0fea02db474",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID='417812395597'\n",
    "REGION='us-west2'\n",
    "BUCKET_URI='gs://my-training-artifacts'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2657b6b8-17b0-4e7a-a454-d31fe3018161",
   "metadata": {},
   "source": [
    "## Initialize Vertex AI (SDK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0108c61b-7a06-48c8-bffd-7da85f2bbf76",
   "metadata": {},
   "outputs": [],
   "source": [
    "aiplatform.init(project=PROJECT_ID, location=REGION, staging_bucket=BUCKET_URI)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa928772-f392-4917-b0c0-1ab5c6bff483",
   "metadata": {},
   "source": [
    "## Setup pre-built contianer for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c10544f7-f248-4221-bcc0-d324aa1e6cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_VERSION = \"tf-cpu.2-9\"\n",
    "DEPLOY_VERSION = \"tf2-cpu.2-9\"\n",
    "TRAIN_IMAGE = \"us-docker.pkg.dev/vertex-ai/training/{}:latest\".format(TRAIN_VERSION)\n",
    "DEPLOY_IMAGE = \"us-docker.pkg.dev/vertex-ai/prediction/{}:latest\".format(DEPLOY_VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ca7270-4c5b-4900-9dee-630ce55942c0",
   "metadata": {},
   "source": [
    "## Define command-line arguments for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45e7bcda-457a-4802-a3d9-325d3a6c9e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "JOB_NAME = \"vertex_custom_training\"\n",
    "MODEL_DIR = \"{}/{}\".format(BUCKET_URI, JOB_NAME)\n",
    "\n",
    "TRAIN_STRATEGY = \"single\"\n",
    "EPOCHS = 20\n",
    "STEPS = 100\n",
    "\n",
    "CMDARGS = [\n",
    "    \"--epochs=\" + str(EPOCHS),\n",
    "    \"--steps=\" + str(STEPS),\n",
    "    \"--distribute=\" + TRAIN_STRATEGY,\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e0dbed-e186-4361-bcb1-67feab3ed238",
   "metadata": {},
   "source": [
    "## Writing down entire training script into a \"task.py\" file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f2748a-4e7c-40d2-903d-63f7a8121e2e",
   "metadata": {},
   "source": [
    "### This task.py will run inside the contianer that we have defined above (could be a custom contianer with all dependencies)\n",
    "#### task.py should have the entire training flow including - \n",
    "- Load and prepared the training data\n",
    "- define model architecure\n",
    "- train model\n",
    "- save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ccb42302-2dc4-4f31-9489-3dcddde878ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting task.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile task.py\n",
    "# Single, Mirror and Multi-Machine Distributed Training\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow\n",
    "from tensorflow.python.client import device_lib\n",
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "from io import BytesIO\n",
    "import numpy as np\n",
    "from tensorflow.python.lib.io import file_io\n",
    "\n",
    "# parse required arguments\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--lr', dest='lr',\n",
    "                    default=0.001, type=float,\n",
    "                    help='Learning rate.')\n",
    "parser.add_argument('--epochs', dest='epochs',\n",
    "                    default=10, type=int,\n",
    "                    help='Number of epochs.')\n",
    "parser.add_argument('--steps', dest='steps',\n",
    "                    default=35, type=int,\n",
    "                    help='Number of steps per epoch.')\n",
    "parser.add_argument('--distribute', dest='distribute', type=str, default='single',\n",
    "                    help='distributed training strategy')\n",
    "args = parser.parse_args()\n",
    "\n",
    "print('Python Version = {}'.format(sys.version))\n",
    "print('TensorFlow Version = {}'.format(tf.__version__))\n",
    "print('TF_CONFIG = {}'.format(os.environ.get('TF_CONFIG', 'Not found')))\n",
    "print('DEVICES', device_lib.list_local_devices())\n",
    "\n",
    "# Single Machine, single compute device\n",
    "if args.distribute == 'single':\n",
    "    if tf.test.is_gpu_available():\n",
    "        strategy = tf.distribute.OneDeviceStrategy(device=\"/gpu:0\")\n",
    "    else:\n",
    "        strategy = tf.distribute.OneDeviceStrategy(device=\"/cpu:0\")\n",
    "# Single Machine, multiple compute device\n",
    "elif args.distribute == 'mirror':\n",
    "    strategy = tf.distribute.MirroredStrategy()\n",
    "# Multiple Machine, multiple compute device\n",
    "elif args.distribute == 'multi':\n",
    "    strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy()\n",
    "\n",
    "# Multi-worker configuration\n",
    "print('num_replicas_in_sync = {}'.format(strategy.num_replicas_in_sync))\n",
    "\n",
    "# Preparing dataset\n",
    "BUFFER_SIZE = 10000\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "def make_datasets_unbatched():\n",
    "    # Load train, validation and test sets\n",
    "    dest = 'gs://data-bucket-417812395597/'\n",
    "    train_x = np.load(BytesIO(\n",
    "        file_io.read_file_to_string(dest+'train_x', binary_mode=True)\n",
    "    ))\n",
    "    train_y = np.load(BytesIO(\n",
    "        file_io.read_file_to_string(dest+'train_y', binary_mode=True)\n",
    "    ))\n",
    "    val_x = np.load(BytesIO(\n",
    "        file_io.read_file_to_string(dest+'val_x', binary_mode=True)\n",
    "    ))\n",
    "    val_y = np.load(BytesIO(\n",
    "        file_io.read_file_to_string(dest+'val_y', binary_mode=True)\n",
    "    ))\n",
    "    test_x = np.load(BytesIO(\n",
    "        file_io.read_file_to_string(dest+'test_x', binary_mode=True)\n",
    "    ))\n",
    "    test_y = np.load(BytesIO(\n",
    "        file_io.read_file_to_string(dest+'test_y', binary_mode=True)\n",
    "    ))\n",
    "    return train_x, train_y, val_x, val_y, test_x, test_y\n",
    "\n",
    "def tf_model():\n",
    "    black_n_white_input = tensorflow.keras.layers.Input(shape=(80, 80, 1))\n",
    "    \n",
    "    enc = black_n_white_input\n",
    "    \n",
    "    #Encoder part\n",
    "    enc = tensorflow.keras.layers.Conv2D(\n",
    "        32, kernel_size=3, strides=2, padding='same'\n",
    "    )(enc)\n",
    "    enc = tensorflow.keras.layers.LeakyReLU(alpha=0.2)(enc)\n",
    "    enc = tensorflow.keras.layers.BatchNormalization(momentum=0.8)(enc)\n",
    "    \n",
    "    enc = tensorflow.keras.layers.Conv2D(\n",
    "        64, kernel_size=3, strides=2, padding='same'\n",
    "    )(enc)\n",
    "    enc = tensorflow.keras.layers.LeakyReLU(alpha=0.2)(enc)\n",
    "    enc = tensorflow.keras.layers.BatchNormalization(momentum=0.8)(enc)\n",
    "    \n",
    "    enc = tensorflow.keras.layers.Conv2D(\n",
    "        128, kernel_size=3, strides=2, padding='same'\n",
    "    )(enc)\n",
    "    enc = tensorflow.keras.layers.LeakyReLU(alpha=0.2)(enc)\n",
    "    enc = tensorflow.keras.layers.BatchNormalization(momentum=0.8)(enc)\n",
    "    \n",
    "    enc = tensorflow.keras.layers.Conv2D(\n",
    "        256, kernel_size=1, strides=2, padding='same'\n",
    "    )(enc)\n",
    "    enc = tensorflow.keras.layers.LeakyReLU(alpha=0.2)(enc)\n",
    "    enc = tensorflow.keras.layers.Dropout(0.5)(enc)\n",
    "    \n",
    "    #Decoder part\n",
    "    dec = enc\n",
    "    \n",
    "    dec = tensorflow.keras.layers.Conv2DTranspose(\n",
    "        256, kernel_size=3, strides=2, padding='same'\n",
    "    )(dec)\n",
    "    dec = tensorflow.keras.layers.Activation('relu')(dec)\n",
    "    dec = tensorflow.keras.layers.BatchNormalization(momentum=0.8)(dec)\n",
    "    \n",
    "    dec = tensorflow.keras.layers.Conv2DTranspose(\n",
    "        128, kernel_size=3, strides=2, padding='same'\n",
    "    )(dec)\n",
    "    dec = tensorflow.keras.layers.Activation('relu')(dec)\n",
    "    dec = tensorflow.keras.layers.BatchNormalization(momentum=0.8)(dec)\n",
    "    \n",
    "    dec = tensorflow.keras.layers.Conv2DTranspose(\n",
    "        64, kernel_size=3, strides=2, padding='same'\n",
    "    )(dec)\n",
    "    dec = tensorflow.keras.layers.Activation('relu')(dec)\n",
    "    dec = tensorflow.keras.layers.BatchNormalization(momentum=0.8)(dec)\n",
    "    \n",
    "    dec = tensorflow.keras.layers.Conv2DTranspose(\n",
    "        32, kernel_size=3, strides=2, padding='same'\n",
    "    )(dec)\n",
    "    dec = tensorflow.keras.layers.Activation('relu')(dec)\n",
    "    dec = tensorflow.keras.layers.BatchNormalization(momentum=0.8)(dec)\n",
    "    \n",
    "    dec = tensorflow.keras.layers.Conv2D(\n",
    "        3, kernel_size=3, padding='same'\n",
    "    )(dec)\n",
    "    \n",
    "    color_image = tensorflow.keras.layers.Activation('tanh')(dec)\n",
    "    \n",
    "    return black_n_white_input, color_image\n",
    "\n",
    "# Build the and compile TF model\n",
    "def build_and_compile_tf_model():\n",
    "    black_n_white_input, color_image = tf_model()\n",
    "    model = tensorflow.keras.models.Model(\n",
    "        inputs=black_n_white_input,\n",
    "        outputs=color_image\n",
    "    )\n",
    "    _optimizer = tensorflow.keras.optimizers.Adam(\n",
    "        learning_rate=0.0002,\n",
    "        beta_1=0.5\n",
    "    )\n",
    "    model.compile(\n",
    "        loss='mse',\n",
    "        optimizer=_optimizer\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# Train the model\n",
    "NUM_WORKERS = strategy.num_replicas_in_sync\n",
    "# Here the batch size scales up by number of workers since\n",
    "# `tf.data.Dataset.batch` expects the global batch size.\n",
    "GLOBAL_BATCH_SIZE = BATCH_SIZE * NUM_WORKERS\n",
    "MODEL_DIR = os.getenv(\"AIP_MODEL_DIR\")\n",
    "\n",
    "train_x, train_y, _, _, _, _ = make_datasets_unbatched()\n",
    "\n",
    "with strategy.scope():\n",
    "    # Creation of dataset, and model building/compiling need to be within\n",
    "    # `strategy.scope()`.\n",
    "    model = build_and_compile_tf_model()\n",
    "\n",
    "model.fit(\n",
    "    train_x,\n",
    "    train_y,\n",
    "    epochs=args.epochs,\n",
    "    steps_per_epoch=args.steps\n",
    ")\n",
    "model.save(MODEL_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1c26e9-44d5-498a-a260-5b7f12e4d0ac",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Define and submit vertex AI training job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "651e5fbc-f220-47cc-9095-9e9fc7511368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training script copied to:\n",
      "gs://my-training-artifacts/aiplatform-2023-04-18-09:25:16.215-aiplatform_custom_trainer_script-0.1.tar.gz.\n",
      "Training Output directory:\n",
      "gs://my-training-artifacts/aiplatform-custom-training-2023-04-18-09:25:16.320 \n",
      "View Training:\n",
      "https://console.cloud.google.com/ai/platform/locations/us-west2/training/3454177351309459456?project=417812395597\n",
      "CustomTrainingJob projects/417812395597/locations/us-west2/trainingPipelines/3454177351309459456 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "View backing custom job:\n",
      "https://console.cloud.google.com/ai/platform/locations/us-west2/training/6460048627602554880?project=417812395597\n",
      "CustomTrainingJob projects/417812395597/locations/us-west2/trainingPipelines/3454177351309459456 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "CustomTrainingJob projects/417812395597/locations/us-west2/trainingPipelines/3454177351309459456 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "CustomTrainingJob projects/417812395597/locations/us-west2/trainingPipelines/3454177351309459456 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "CustomTrainingJob projects/417812395597/locations/us-west2/trainingPipelines/3454177351309459456 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "CustomTrainingJob projects/417812395597/locations/us-west2/trainingPipelines/3454177351309459456 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "CustomTrainingJob projects/417812395597/locations/us-west2/trainingPipelines/3454177351309459456 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "CustomTrainingJob run completed. Resource name: projects/417812395597/locations/us-west2/trainingPipelines/3454177351309459456\n",
      "Model available at projects/417812395597/locations/us-west2/models/1132109948516302848\n"
     ]
    }
   ],
   "source": [
    "job = aiplatform.CustomTrainingJob(\n",
    "    display_name=JOB_NAME,\n",
    "    script_path=\"task.py\",\n",
    "    container_uri=TRAIN_IMAGE,\n",
    "    requirements=[],\n",
    "    model_serving_container_image_uri=DEPLOY_IMAGE,\n",
    ")\n",
    "\n",
    "MODEL_DISPLAY_NAME = \"tf_bnw_to_color\"\n",
    "\n",
    "# Start the training job\n",
    "model = job.run(\n",
    "    model_display_name=MODEL_DISPLAY_NAME,\n",
    "    args=CMDARGS,\n",
    "    machine_type = \"n1-standard-16\",\n",
    "    replica_count=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7492a1ce-594b-41d4-bedf-a12f3e9c3c79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d44c735-10f4-4eac-99c4-42edb12e3bf9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-8.m103",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-8:m103"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
