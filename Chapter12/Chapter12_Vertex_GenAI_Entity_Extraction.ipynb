{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vertex AI MLOps Book - Chapter 12 - GenAI - Document Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at: https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Objective:** In this notebook we will use Veretx AI PALM Text model to extract ententities from a scanned PDF containing Patent Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up and import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "70lij66aJZoV",
    "outputId": "4341d94e-5fc2-48a9-9c1a-6ed29ae62b16"
   },
   "outputs": [],
   "source": [
    "#install dependencies\n",
    "!pip install google-cloud-aiplatform --upgrade\n",
    "!pip install google-cloud-documentai\n",
    "#!pip install google-cloud-storage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "GeB5akYjIOnG",
    "outputId": "086e434c-35a9-478c-ca6d-394916ca91b9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "_tvj408TIDbd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-18 06:46:42.839955: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-18 06:46:42.886715: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-18 06:46:42.886752: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-18 06:46:42.888293: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-18 06:46:42.895680: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-18 06:46:42.896464: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "#import libraries\n",
    "\n",
    "#from google.api_core.client_options import ClientOptions\n",
    "from google.cloud import documentai\n",
    "import vertexai\n",
    "from vertexai.preview.language_models import TextGenerationModel\n",
    "\n",
    "#from PIL import Image, ImageDraw\n",
    "#import os\n",
    "import pandas as pd\n",
    "\n",
    "#from pdf2image import convert_from_path, convert_from_bytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WWi0T7F7JQmj"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Authentication "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and run this cell if running notebook locally\n",
    "#! gcloud auth login"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Uncomment and run the following section only if using Google Colab Notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "03otjfCP8Eh2"
   },
   "outputs": [],
   "source": [
    "\n",
    "#from google.colab import auth as google_auth\n",
    "#google_auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Provide GCP Project ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = \"jsb-alto\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define path to the pdf file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "vyu4sq9n8Euv"
   },
   "outputs": [],
   "source": [
    "file_path='./sample_data/US_PTO_Sample.pdf'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display and review the PDF File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"700\"\n",
       "            src=\"./sample_data/US_PTO_Sample.pdf\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fe29d70bd60>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from IPython.display import IFrame\n",
    "IFrame(file_path, width=800, height=700)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 817
    },
    "id": "x9GfXM3XGy86",
    "outputId": "a87f25ea-d638-42e2-db0e-e4fc6f1a3635"
   },
   "source": [
    "# Use GCP Document AI to OCR the PDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stop if you have not already created/provisioned a Doc AI OCR parser in GCP Document AI\n",
    "See \"Chapter 13, Document AI – an End-to-End Solution for Processing Documents\" for more details.\n",
    "\n",
    "Key Steps to deploy Document AI - OCR Parser before you can proceed:\n",
    "1. Navigate to GCP Console and in the search bar search for \"Document AI\" and click on it\n",
    "2. Click on 'Processor Gallery'\n",
    "3. Click on 'Create Processor' button under 'Document OCR'\n",
    "4. Provide a new processor name and click 'Create'\n",
    "5. Copy the 'Processor Id' under 'basic information section.\n",
    "\n",
    "Enter the processor ID in the 'Doc AI configuration section below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "iVni3cEcXPkV"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_LpZ91pqHMco"
   },
   "source": [
    "## Doc AI Configurations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use this config. for PDF Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For PDF Docs\n",
    "ocr_output = process_document_sample(\n",
    "  project_id=PROJECT_ID, # Replace with your own processor ID\n",
    "  location=\"us\",\n",
    "  processor_id=\"2fb6b1be15c7f2d\", # Replace with your own processor ID\n",
    "    mime_type = 'application/pdf',\n",
    "    field_mask = None,\n",
    "  file_path= file_path\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use this config.for TIFF files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "Y-2rk-TcvWIx"
   },
   "outputs": [],
   "source": [
    "##For TIFF docs uncomment the below section and run\n",
    "#ocr_output = process_document_sample(\n",
    "#  project_id=\"398507275014\",\n",
    "#  location=\"us\",\n",
    "#  processor_id=\"2fb6b1be15c7f2d\",\n",
    "#    mime_type = 'image/tiff',\n",
    "#    field_mask = None,\n",
    "#  file_path=\"./genai_demo_data/demo_data.tiff\"\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to OCR the PDF using Document AI\n",
    "def process_document_sample(\n",
    "    project_id: str,\n",
    "    location: str,\n",
    "    processor_id: str,\n",
    "    file_path: str,\n",
    "    mime_type: str,\n",
    "    field_mask: str = None,\n",
    "):\n",
    "\n",
    "    client = documentai.DocumentProcessorServiceClient()\n",
    "\n",
    "    name = client.processor_path(project_id, location, processor_id)\n",
    "\n",
    "    # Import the file into memory\n",
    "    with open(file_path, \"rb\") as image:\n",
    "        image_content = image.read()\n",
    "\n",
    "    # Load the image content\n",
    "    raw_document = documentai.RawDocument(content=image_content, mime_type=mime_type)\n",
    "\n",
    "\n",
    "    request = documentai.ProcessRequest(\n",
    "        name=name, raw_document=raw_document\n",
    "    )\n",
    "\n",
    "    result = client.process_document(request=request)\n",
    "\n",
    "\n",
    "    document = result.document\n",
    "\n",
    "    # Read the text recognition output from the processor\n",
    "    return(document.text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4N90n_fLXUQK",
    "outputId": "96e32946-0928-4210-8b62-a58943f1e7be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12) United States Patent\n",
      "Lethin et al.\n",
      "(54) METHODS AND APPARATUS FOR LOCAL\n",
      "MEMORY COMPACTION\n",
      "(75) Inventors: Richard A. Lethin, New York, NY (US);\n",
      "Allen K. Leung, New York, NY (US);\n",
      "Benoit J. Meister, New York, NY (US);\n",
      "Nicolas T. Vasilache, New York, NY\n",
      "(US); David E. Wohlford, Portland, OR\n",
      "(US)\n",
      "(73) Assignee: Reservoir Labs, Inc., New York, NY\n",
      "(US)\n",
      "(*) Notice:\n",
      "(21) Appl. No.: 12/365,780\n",
      "(22) Filed:\n",
      "Feb. 4, 2009\n",
      "(65)\n",
      "Prior Publication Data\n",
      "US 2010/0192138 A1 Jul. 29, 2010\n",
      "Related U.S. Application Data\n",
      "(60) Provisional application No. 61/065,294, filed on Feb.\n",
      "8, 2008.\n",
      "(51) Int. Cl.\n",
      "(56)\n",
      "Subject to any disclaimer, the term of this\n",
      "patent is extended or adjusted under 35\n",
      "U.S.C. 154(b) by 1287 days.\n",
      "G06F 9/45\n",
      "(52) U.S. CI.\n",
      "USPC\n",
      "(58)\n",
      "5,442,699 A\n",
      "5,442,797 A\n",
      "5,613,136 A\n",
      "(2006.01)\n",
      "Field of Classification Search\n",
      "USPC\n",
      "See application file for complete search history.\n",
      "References Cited\n",
      "U.S. PATENT DOCUMENTS\n",
      "717/151\n",
      "8/1995 Arnold et al.\n",
      "8/1995 Casavant et al.\n",
      "3/1997 Casavant et al.\n",
      "717/151\n",
      "Start\n",
      "(10) Patent No.:\n",
      "(45) Date of Patent:\n",
      "5,742,814 A\n",
      "5,920,854 A\n",
      "5,953,531 A\n",
      "6,006,033 A\n",
      "6,018,735 A\n",
      "6,038,398 A\n",
      "6,131,092 A\n",
      "6,279,113 B1\n",
      "6,327,699 B1\n",
      "6,338,057 B1\n",
      "6,651,246 B1\n",
      "6,754,650 B2\n",
      "OTHER PUBLICATIONS\n",
      "International Report on Patentability dated Mar. 31, 2011 for PCT\n",
      "Application No. PCT/US2009/057194.\n",
      "Receive source code representing loops\n",
      "with arbitrary parametric affine iteration\n",
      "domains containing at least one array\n",
      "reference\n",
      "Complete\n",
      "(Continued)\n",
      "Primary Examiner - Idriss N Alrobaye\n",
      "Assistant Examiner - Brooke Taylor\n",
      "(74) Attorney, Agent, or Firm - Goodwin Procter LLP\n",
      "Identify inefficiencies in memory usage\n",
      "related to the memory footprint of the at\n",
      "least one array\n",
      "(57)\n",
      "ABSTRACT\n",
      "Methods, apparatus and computer software product for local\n",
      "memory compaction are provided. In an exemplary embodi-\n",
      "ment, a processor in connection with a memory compaction\n",
      "module identifies inefficiencies in array references contained\n",
      "within in received source code, allocates a local array and\n",
      "maps the data from the inefficient array reference to the local\n",
      "array in a manner which improves the memory size require-\n",
      "ments for storing and accessing the data. In another embodi-\n",
      "ment, a computer software product implementing a local\n",
      "memory compaction module is provided. In a further embodi-\n",
      "ment a computing apparatus is provided. The computing\n",
      "apparatus is configured to improve the efficiency of data\n",
      "storage in array references. This Abstract is provided for the\n",
      "sole purpose of complying with the Abstract requirement\n",
      "rules. This Abstract is submitted with the explicit understand-\n",
      "ing that it will not be used to interpret or to limit the scope or\n",
      "the meaning of the claims.\n",
      "39 Claims, 9 Drawing Sheets\n",
      "Allocate at least one local array\n",
      "Map a portion of the at least one array to\n",
      "one of the at least one local array.\n",
      "US008661422B2\n",
      "10\n",
      "20\n",
      "US 8,661,422 B2\n",
      "Feb. 25, 2014\n",
      "30\n",
      "4/1998 Balasa et al.\n",
      "7/1999 Kirsch et al.\n",
      "9/1999 Megiddo et al.\n",
      "12/1999 Heisch\n",
      "1/2000 Hunter\n",
      "3/2000 Schooler\n",
      "10/2000 Masand\n",
      "8/2001 Vaidya\n",
      "12/2001 Larus et al.\n",
      "1/2002 Weeks\n",
      "11/2003 Archambault et al.\n",
      "6/2004 Cho et al.\n",
      "(Continued)\n",
      "40\n",
      "(56)\n",
      "References Cited\n",
      "U.S. PATENT DOCUMENTS\n",
      "8/2004 Danckaert et al.\n",
      "8/2004 Fritchman\n",
      "Akaboshi\n",
      "6,772,415 B1\n",
      "6,785,677 B1\n",
      "6,792,546 B1\n",
      "6,880,087 B1\n",
      "6,912,526 B2\n",
      "6,952,694 B2\n",
      "6,952,821 B2\n",
      "7,086,038 B2\n",
      "7,185,327 B2\n",
      "7,225,188 B1\n",
      "7,260,558 B1\n",
      "7,594,260 B2\n",
      "7,634,566 B2\n",
      "7,757,222 B2\n",
      "10/2005 Mathur et al.\n",
      "10/2005 Schreiber\n",
      "8/2006 Cronquist et al.\n",
      "2/2007 Scales\n",
      "5/2007 Gai et al.\n",
      "8/2007 Cheng et al.\n",
      "9/2009 Porras et al.\n",
      "Turner et al.\n",
      "Liao et al.\n",
      "12/2009\n",
      "7/2010\n",
      "8,087,010 B2 12/2011 Eichenberger et al.\n",
      "8,108,845 B2 1/2012 Little et al.\n",
      "7/2012 Eng\n",
      "8,230,408 B2\n",
      "8,250,550 B2 8/2012 Luszczek et al.\n",
      "8,255,890 B2 8/2012 Luszczek et al.\n",
      "8,307,347 B2 11/2012 Austin et al.\n",
      "2002/0021838 Al 2/2002 Richardson et al.\n",
      "2003/0097652 Al 5/2003 Roediger et al.\n",
      "2004/0034754 A1 2/2004 Schreiber\n",
      "2004/0068501 A1 4/2004 McGoveran\n",
      "2005/0114700 A1 5/2005 Barrie et al.\n",
      "2006/0048121 Al 3/2006 Blainey et al.\n",
      "2006/0048123 Al 3/2006 Martin\n",
      "2006/0085858 Al\n",
      "2007/0033367 A1*\n",
      "2007/0074195 Al\n",
      "2007/0192861 Al\n",
      "2008/0010680 Al\n",
      "2009/0037889 A1*\n",
      "4/2006 Noel et al.\n",
      "2/2007 Sakarda et al.\n",
      "3/2007 Liao et al.\n",
      "8/2007 Varghese et al.\n",
      "1/2008 Cao et al.\n",
      "2/2009 Li et al.\n",
      "2009/0083724 A1* 3/2009 Eichenberger et al.\n",
      "2009/0119677 Al 5/2009 Stefansson et al.\n",
      "9/2004 Shanklin et al.\n",
      "4/2005 Carter\n",
      "6/2005\n",
      "2009/0259997 A1 10/2009 Grover et al.\n",
      "2009/0307673 Al\n",
      "2010/0050164 Al\n",
      "2010/0162225 A1\n",
      "12/2009 Eichenberger et al.\n",
      "2/2010 Van De Waerdt et al.\n",
      "6/2010 Huang et al.\n",
      "OTHER PUBLICATIONS\n",
      "US 8,661,422 B2\n",
      "Page 2\n",
      "711/170\n",
      "717/140\n",
      "717/160\n",
      "International Search Report and the Written Opinion dated Mar. 18,\n",
      "2010 for PCT Application No. PCT/US2009/057194.\n",
      "Software Tools to Optimize BMD Radar Algorithms to COTS Hard-\n",
      "ware: Phase II Proposal, Reservoir Labs, Inc., Topic No. MDA06-\n",
      "031, Proposal No. B2-1415.\n",
      "Optimizing and Mapping Tool Chain for FPGA Programming-\n",
      "Phase II Proposal, Reservoir Labs, Inc., Topic No. SB062-006, Pro-\n",
      "posal No. D2-0627.\n",
      "Darte and Vivien's Algorithm, \"Chapter 5: Parallelism Detection In\n",
      "Nested Loops\", pp. 193-226.\n",
      "\"The Cell Roadmap\", Published on PPCNUX at http://www.ppcnux.\n",
      "com/?q=print/6666.\n",
      "\"ClearSpeed™ Introductory Programming Manual The\n",
      "ClearSpeed Software Development Kit\", ClearSpeed Technology\n",
      "Inc. 2007.\n",
      "\"ClearSpeed™ ClearSpeed Programming Model: An introduction\",\n",
      "ClearSpeed Technology Inc. 2007.\n",
      "\"ClearSpeed™ ClearSpeed Programming Model: Card-side Librar-\n",
      "ies\", ClearSpeed Technology Inc. 2007.\n",
      "\"ClearSpeed™ ClearSpeed Programming Model: Optimizing Per-\n",
      "formance\", ClearSpeed Technology Inc. 2007.\n",
      "Ayers et al, Aggressive inlining, PLDI '92 Las Vegas, NV, USA.\n",
      "Bastoul, \"Efficient Code Generation for Automatic Parallelization\n",
      "and Optimization\", Proceedings of the Second International Sympo-\n",
      "sium on Parallel and Distributed Computing, 2003.\n",
      "Bastoul, \"Code Generation in the Polyhedral Model Is Easier Than\n",
      "You Think\", Proceedings of the 13th International Conference on\n",
      "Parallel Architecture and Compilation Techniques, 2004.\n",
      "Bastoul et al, \"Putting Polyhedral Loop Transformations to Work\",\n",
      "INRIA, No. 4902, Jul. 2003.\n",
      "Bondhugula et al, \"Automatic Mapping of Nested Loops to FPGAs\",\n",
      "OSU, Mar. 19, 2007.\n",
      "Bondhugula et al, \"A Practical and Fully Automatic Polyhedral Pro-\n",
      "gram Optimization System\", OSU OSU-CISRC-10/07-TR70, Dec.\n",
      "14, 2007.\n",
      "Cifuentes, \"Structuring Decompiled Graphs\", Department of Com-\n",
      "puter Science, Univ. of Tasmania, 1994.\n",
      "Cifuentes, \"Structuring Decompiled Graphs\", Department of Com-\n",
      "puter Science, Univ. of Tasmania, 1996.\n",
      "Clauss et al, \"Deriving Formulae to Count Solutions to Parameterized\n",
      "Linear Systems using Ehrhart Polynomials: Applications to the\n",
      "Analysis of Nested-Loop Programs\", Apr. 10, 1997.\n",
      "Collard et al, \"Automatic Generation of Data Parallel Code\", Pro-\n",
      "ceedings of the Fourth International Workshop on Compilers for\n",
      "Parallel Computers, Dec. 1993.\n",
      "Collberg et al, \"Manufacturing Cheap, Resilient, and Stealthy\n",
      "Opaque Constructs\", POPL 98, San Diego, CA 1998.\n",
      "Darte et al, \"Revisiting the decomposition of Karp, Miller and\n",
      "Winograd\", Parallel Processing Letters, 1995.\n",
      "Feautrier, \"Array Expansion\", Labratoire PRISM, Jul. 1998.\n",
      "Feautrier, \"Some efficient solutions to the affine scheduling problem\n",
      "Part I One-dimensional Time\", Laboratoire MASI, Institute Blaise\n",
      "Pascal, Universite de Versailles St-Quentin, Apr. 23, 1993.\n",
      "Ferrante et al, \"The Program Dependence Graph and Its Use in\n",
      "Optimization\", ACM Transactions on Programming Languages and\n",
      "Systems, vol. 9, No. 3, Jul. 1987, pp. 319-349.\n",
      "Franke et al, \"Compiler Transformation of Pointers to Explicit Array\n",
      "Accesses in DSP Applications\", Institute for Computing Systems\n",
      "Architecture (ICSA), University of Edinburgh.\n",
      "Gautam et al, \"The Z-Polyhedral Model\", PPOPP'07, San Jose, CA\n",
      "Mar. 14-17, 2007.\n",
      "Griebl, \"On the Mechanical Tiling of Space-Time Mapped Loop\n",
      "Nests\", Fakultat fur Mthemetik and Informatik, Universitat Passau,\n",
      "Germany.\n",
      "Griebl et al, \"Space-Time Mapping and Tiling: A Helpful Combina-\n",
      "tion\", Concurrency and Comput.: Pract. Exper. 2004, 16:221-246.\n",
      "Griebl, \"Automatic Parallelization of Loop Programs for Distributed\n",
      "Memory Architectures\" Fakultat fur Mathematik und Informatik,\n",
      "Jun. 2, 2004.\n",
      "Griebl et al, \"Forward Communication Only Placements and their\n",
      "Use for Parallel Program Construction\", University of Passau.\n",
      "Irigoin et al, \"Supernode Partitioning\", Proceedings of the 15th\n",
      "Annual ACM, SIGACT-SIGPLAN Symposium on Principles of Pro-\n",
      "gramming Languages, San Diego, CA, Jan. 1988.\n",
      "Jimenez et al, \"Register Tiling in Nonrectangular Iteration Spaces\",\n",
      "ACM Transactions on Programming Languages and Systems, vol.\n",
      "24, No. 4, pp. 409-453, Jul. 2002.\n",
      "Kandemir et al, \"Optimizing Spatial Locality in Loop Nests using\n",
      "Linear Algebra\", Proc. 7th International Workshop on Compliers for\n",
      "Parallel Computers, Sweden Jun. 1998.\n",
      "Lethin, \"Software Tools to Optimize BMD Radar Algorithms to\n",
      "COTS Hardware-Final Report\", Sep. 12, 2007.\n",
      "Lethin et al, \"Mapping Loops for the ClearSpeed Processor Using the\n",
      "R-Stream Compiler\", Feb. 4, 2008.\n",
      "Lethin et al, \"The R-Stream 3.0 Compiler\", Feb. 4, 2008.\n",
      "Lim et al, \"Maximizing Parallelism and Minimizing Synchronization\n",
      "with Affine Transforms\", 24th Annual ACM SIGPLAN-SIGACT\n",
      "Symposium on Principles of Programming Languages, Paris, France,\n",
      "Jan. 1997.\n",
      "Loechner et al, \"Precise Data Locality Optimization of Nested\n",
      "Loops\", The Journal of Supercomputing, 21, pp. 37-76, 2002.\n",
      "Meister et al, \"Optimizing and Mapping Tool Chain for FPGA Pro-\n",
      "gramming Final Report Phase 1 SBIR Project\", Sep. 28, 2007.\n",
      "Pop et al, \"Induction Variable Analysis with Delayed Abstractions\",\n",
      "ACM Transactions on Architecture and Code Optimization, vol. V,\n",
      "No. N, pp. 1-30, Aug. 2005.\n",
      "Pop et al, \"Fast Recognition of Scalar Evolutions on Three-Address\n",
      "SSA Code\", CRI/ENSMP Research Report, A/354/CRI, Apr. 1,\n",
      "2004.\n",
      "Quillere et al, \"Generation of Efficient Nested Loops from Polyhe-\n",
      "dra\" 2000 Kluwer Academic Publishers, 2000.\n",
      "Quinton et al, \"On Manipulating Z-polyhedra\", IRISA, Publication\n",
      "Interne No. 1016, Jul. 1996.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Print the first 1000 characters of the OCR output\n",
    "print(ocr_output[:32000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ylSAjPgvHp4k"
   },
   "source": [
    "### Run the OCR results above through the Vertex AI GenAI/PALM Model to extact entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "rlK_Egd47rKn"
   },
   "outputs": [],
   "source": [
    "# Define the function to process OCR output through Vertex AI GenAI Model\n",
    "\n",
    "def predict_large_language_model_sample(\n",
    "    project_id: str,\n",
    "    model_name: str,\n",
    "    temperature: float,\n",
    "    max_decode_steps: int,\n",
    "    top_p: float,\n",
    "    top_k: int,\n",
    "    content: str,\n",
    "    location: str = \"us-central1\",\n",
    "    tuned_model_name: str = \"\",\n",
    "    ) :\n",
    "    \"\"\"Predict using a Large Language Model.\"\"\"\n",
    "    vertexai.init(project=project_id, location=location)\n",
    "    model = TextGenerationModel.from_pretrained(model_name)\n",
    "    if tuned_model_name:\n",
    "      model = model.get_tuned_model(tuned_model_name)\n",
    "    response = model.predict(\n",
    "        content,\n",
    "        temperature=temperature,\n",
    "        max_output_tokens=max_decode_steps,\n",
    "        top_k=top_k,\n",
    "        top_p=top_p,)\n",
    "    print(f\"Response from Model: {response.text}\")\n",
    "    return(response.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enter the prompt to be used for entity etxraction from the document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "t3h-4vIgtgh0"
   },
   "outputs": [],
   "source": [
    "prompt_suffix = '''What is the name of the inventor(s) and their respective locations. Provide answer in form of a table with first column providing Inventor's name, second column providing their location and third column providing Patent Number??'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine the OCR output and the prompt/question above to create full input text to be fed to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "id": "rR3djNdVZsTs",
    "outputId": "412e3b47-57b0-4a89-e04f-7e06797843ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arte and Vivien's Algorithm, \"Chapter 5: Parallelism Detection In\n",
      "Nested Loops\", pp. 193-226.\n",
      "\"The Cell Roadmap\", Published on PPCNUX at http://www.ppcnux.\n",
      "com/?q=print/6666.\n",
      "\"ClearSpeed™ Introductory Programming Manual The\n",
      "ClearSpeed Software Development Kit\", ClearSpeed Technology\n",
      "Inc. 2007.\n",
      "\"ClearSpeed™ ClearSpeed Programming Model: An introduction\",\n",
      "ClearSpeed Technology Inc. 2007.\n",
      "\"ClearSpeed™ ClearSpeed Programming Model: Card-side Librar-\n",
      "ies\", ClearSpeed Technology Inc. 2007.\n",
      "\"ClearSpeed™ ClearSpeed Programming Model: Optimizing Per-\n",
      "formance\", ClearSpeed Technology Inc. 2007.\n",
      "Ayers et al, Aggressive inlining, PLDI '92 Las Vegas, NV, USA.\n",
      "Bastoul, \"Efficient Code Generation for Automatic Parallelization\n",
      "and Optimization\", Proceedings of the Second International Sympo-\n",
      "sium on Parallel and Distributed Computing, 2003.\n",
      "Bastoul, \"Code Generation in the Polyhedral Model Is Easier Than\n",
      "You Think\", Proceedings of the 13th International Conference on\n",
      "Parallel Architecture and Compilation Techniques, 2004.\n",
      "Bastoul et al, \"Putting Polyhedral Loop Transformations to Work\",\n",
      "INRIA, No. 4902, Jul. 2003.\n",
      "Bondhugula et al, \"Automatic Mapping of Nested Loops to FPGAs\",\n",
      "OSU, Mar. 19, 2007.\n",
      "Bondhugula et al, \"A Practical and Fully Automatic Polyhedral Pro-\n",
      "gram Optimization System\", OSU OSU-CISRC-10/07-TR70, Dec.\n",
      "14, 2007.\n",
      "Cifuentes, \"Structuring Decompiled Graphs\", Department of Com-\n",
      "puter Science, Univ. of Tasmania, 1994.\n",
      "Cifuentes, \"Structuring Decompiled Graphs\", Department of Com-\n",
      "puter Science, Univ. of Tasmania, 1996.\n",
      "Clauss et al, \"Deriving Formulae to Count Solutions to Parameterized\n",
      "Linear Systems using Ehrhart Polynomials: Applications to the\n",
      "Analysis of Nested-Loop Programs\", Apr. 10, 1997.\n",
      "Collard et al, \"Automatic Generation of Data Parallel Code\", Pro-\n",
      "ceedings of the Fourth International Workshop on Compilers for\n",
      "Parallel Computers, Dec. 1993.\n",
      "Collberg et al, \"Manufacturing Cheap, Resilient, and Stealthy\n",
      "Opaque Constructs\", POPL 98, San Diego, CA 1998.\n",
      "Darte et al, \"Revisiting the decomposition of Karp, Miller and\n",
      "Winograd\", Parallel Processing Letters, 1995.\n",
      "Feautrier, \"Array Expansion\", Labratoire PRISM, Jul. 1998.\n",
      "Feautrier, \"Some efficient solutions to the affine scheduling problem\n",
      "Part I One-dimensional Time\", Laboratoire MASI, Institute Blaise\n",
      "Pascal, Universite de Versailles St-Quentin, Apr. 23, 1993.\n",
      "Ferrante et al, \"The Program Dependence Graph and Its Use in\n",
      "Optimization\", ACM Transactions on Programming Languages and\n",
      "Systems, vol. 9, No. 3, Jul. 1987, pp. 319-349.\n",
      "Franke et al, \"Compiler Transformation of Pointers to Explicit Array\n",
      "Accesses in DSP Applications\", Institute for Computing Systems\n",
      "Architecture (ICSA), University of Edinburgh.\n",
      "Gautam et al, \"The Z-Polyhedral Model\", PPOPP'07, San Jose, CA\n",
      "Mar. 14-17, 2007.\n",
      "Griebl, \"On the Mechanical Tiling of Space-Time Mapped Loop\n",
      "Nests\", Fakultat fur Mthemetik and Informatik, Universitat Passau,\n",
      "Germany.\n",
      "Griebl et al, \"Space-Time Mapping and Tiling: A Helpful Combina-\n",
      "tion\", Concurrency and Comput.: Pract. Exper. 2004, 16:221-246.\n",
      "Griebl, \"Automatic Parallelization of Loop Programs for Distributed\n",
      "Memory Architectures\" Fakultat fur Mathematik und Informatik,\n",
      "Jun. 2, 2004.\n",
      "Griebl et al, \"Forward Communication Only Placements and their\n",
      "Use for Parallel Program Construction\", University of Passau.\n",
      "Irigoin et al, \"Supernode Partitioning\", Proceedings of the 15th\n",
      "Annual ACM, SIGACT-SIGPLAN Symposium on Principles of Pro-\n",
      "gramming Languages, San Diego, CA, Jan. 1988.\n",
      "Jimenez et al, \"Register Tiling in Nonrectangular Iteration Spaces\",\n",
      "ACM Transactions on Programming Languages and Systems, vol.\n",
      "24, No. 4, pp. 409-453, Jul. 2002.\n",
      "Kandemir et al, \"Optimizing Spatial Locality in Loop Nests using\n",
      "Linear Algebra\", Proc. 7th International Workshop on Compliers for\n",
      "Parallel Computers, Sweden Jun. 1998.\n",
      "Lethin, \"Software Tools to Optimize BMD Radar Algorithms to\n",
      "COTS Hardware-Final Report\", Sep. 12, 2007.\n",
      "Lethin et al, \"Mapping Loops for the ClearSpeed Processor Using the\n",
      "R-Stream Compiler\", Feb. 4, 2008.\n",
      "Lethin et al, \"The R-Stream 3.0 Compiler\", Feb. 4, 2008.\n",
      "Lim et al, \"Maximizing Parallelism and Minimizing Synchronization\n",
      "with Affine Transforms\", 24th Annual ACM SIGPLAN-SIGACT\n",
      "Symposium on Principles of Programming Languages, Paris, France,\n",
      "Jan. 1997.\n",
      "Loechner et al, \"Precise Data Locality Optimization of Nested\n",
      "Loops\", The Journal of Supercomputing, 21, pp. 37-76, 2002.\n",
      "Meister et al, \"Optimizing and Mapping Tool Chain for FPGA Pro-\n",
      "gramming Final Report Phase 1 SBIR Project\", Sep. 28, 2007.\n",
      "Pop et al, \"Induction Variable Analysis with Delayed Abstractions\",\n",
      "ACM Transactions on Architecture and Code Optimization, vol. V,\n",
      "No. N, pp. 1-30, Aug. 2005.\n",
      "Pop et al, \"Fast Recognition of Scalar Evolutions on Three-Address\n",
      "SSA Code\", CRI/ENSMP Research Report, A/354/CRI, Apr. 1,\n",
      "2004.\n",
      "Quillere et al, \"Generation of Efficient Nested Loops from Polyhe-\n",
      "dra\" 2000 Kluwer Academic Publishers, 2000.\n",
      "Quinton et al, \"On Manipulating Z-polyhedra\", IRISA, Publication\n",
      "Interne No. 1016, Jul. 1996.\n",
      "What is the name of the inventor(s) and their respective locations. Provide answer in form of a table with first column providing Inventor's name, second column providing their location and third column providing Patent Number??\n"
     ]
    }
   ],
   "source": [
    "ocr_text = ocr_output+prompt_suffix\n",
    "print(ocr_text[5000:20000]) #Limiting to 20K characters in teh notebook. Model can handle 8K Tokens = ~32K Characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feed the input prompt to the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tYMmq3tfaW5c",
    "outputId": "9fc304a3-8066-4d34-fc66-13fa6bccbdac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response from Model: | Inventor | Location | Patent Number |\n",
      "|---|---|---|\n",
      "| Richard A. Lethin | New York, NY (US) | 8,661,422 B2 |\n",
      "| Allen K. Leung | New York, NY (US) | 8,661,422 B2 |\n",
      "| Benoit J. Meister | New York, NY (US) | 8,661,422 B2 |\n",
      "| Nicolas T. Vasilache | New York, NY (US) | 8,661,422 B2 |\n",
      "| David E. Wohlford | Portland, OR (US) | 8,661,422 B2 |\n"
     ]
    }
   ],
   "source": [
    "# Process the full Input Text through the GenAI Model\n",
    "llm_output = predict_large_language_model_sample(PROJECT_ID, #GCP Project\n",
    "                                                 \"text-bison@001\", #LLM Model \n",
    "                                                 0.2, #Temperature\n",
    "                                                 256, #Max output tokens\n",
    "                                                 0.8, #Top K\n",
    "                                                 40,  #Top P\n",
    "                                                 ocr_text, \n",
    "                                                 \"us-central1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print the response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x-fT8JlIag9E",
    "outputId": "ce8aaa70-6470-4835-f9ab-7f6fa321e78b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Inventor | Location | Patent Number |\n",
      "|---|---|---|\n",
      "| Richard A. Lethin | New York, NY (US) | 8,661,422 B2 |\n",
      "| Allen K. Leung | New York, NY (US) | 8,661,422 B2 |\n",
      "| Benoit J. Meister | New York, NY (US) | 8,661,422 B2 |\n",
      "| Nicolas T. Vasilache | New York, NY (US) | 8,661,422 B2 |\n",
      "| David E. Wohlford | Portland, OR (US) | 8,661,422 B2 |\n"
     ]
    }
   ],
   "source": [
    "#Print the answer received from LLM. \n",
    "#In this Patent document use case, answer should the name of the inventors\n",
    "print(llm_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WdO2uNTX53w4",
    "tags": []
   },
   "source": [
    "## Response from the LLM should look like the table below:\n",
    "\n",
    "| Inventor | Location |\n",
    "|---|---|\n",
    "| Richard A. Lethin | New York, NY (US) |\n",
    "| Allen K. Leung | New York, NY (US) |\n",
    "| Benoit J. Meister | New York, NY (US) |\n",
    "| Nicolas T. Vasilache | New York, NY (US) |\n",
    "| David E. Wohlford | Portland, OR (US) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "WkB9bacP2b_Q"
   },
   "outputs": [],
   "source": [
    "import io\n",
    "\n",
    "output = pd.read_csv(io.StringIO(llm_output), sep='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = output.dropna(axis=1, how='all')\n",
    "output = output.dropna(axis=0, how='all')\n",
    "# remove special character\n",
    "output.columns = output.columns.str.replace(' ', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Inventor</th>\n",
       "      <th>Location</th>\n",
       "      <th>PatentNumber</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Richard A. Lethin</td>\n",
       "      <td>New York, NY (US)</td>\n",
       "      <td>8,661,422 B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Allen K. Leung</td>\n",
       "      <td>New York, NY (US)</td>\n",
       "      <td>8,661,422 B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Benoit J. Meister</td>\n",
       "      <td>New York, NY (US)</td>\n",
       "      <td>8,661,422 B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nicolas T. Vasilache</td>\n",
       "      <td>New York, NY (US)</td>\n",
       "      <td>8,661,422 B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>David E. Wohlford</td>\n",
       "      <td>Portland, OR (US)</td>\n",
       "      <td>8,661,422 B2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Inventor             Location    PatentNumber\n",
       "0                     ---                  ---             ---\n",
       "1      Richard A. Lethin    New York, NY (US)    8,661,422 B2 \n",
       "2         Allen K. Leung    New York, NY (US)    8,661,422 B2 \n",
       "3      Benoit J. Meister    New York, NY (US)    8,661,422 B2 \n",
       "4   Nicolas T. Vasilache    New York, NY (US)    8,661,422 B2 \n",
       "5      David E. Wohlford    Portland, OR (US)    8,661,422 B2 "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Push to BQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "from google.cloud import bigquery\n",
    "import pandas\n",
    "import pytz\n",
    "\n",
    "# Construct a BigQuery client object.\n",
    "client = bigquery.Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modify the table_id in next cell to table name you want to use\n",
    "At the very least replace the 'jsb-alto' to your project name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set table_id to the ID of the table to create.\n",
    "table_id = \"jsb-alto.entity_extract.patent_data_extract\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 6 rows and 3 columns to jsb-alto.entity_extract.patent_data_extract\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "dataframe = output\n",
    "\n",
    "\n",
    "job_config = bigquery.LoadJobConfig(\n",
    "    # Specify a (partial) schema. All columns are always written to the\n",
    "    # table. The schema is used to assist in data type definitions.\n",
    "    schema=[\n",
    "        # Specify the type of columns whose type cannot be auto-detected. For\n",
    "        # example the \"title\" column uses pandas dtype \"object\", so its\n",
    "        # data type is ambiguous.\n",
    "        bigquery.SchemaField(\"Inventor\", bigquery.enums.SqlTypeNames.STRING),\n",
    "        # Indexes are written if included in the schema by name.\n",
    "        bigquery.SchemaField(\"Location\", bigquery.enums.SqlTypeNames.STRING),\n",
    "        # Indexes are written if included in the schema by name.\n",
    "        bigquery.SchemaField(\"PatentNumber\", bigquery.enums.SqlTypeNames.STRING),\n",
    "    ],\n",
    "    # Optionally, set the write disposition. BigQuery appends loaded rows\n",
    "    # to an existing table by default, but with WRITE_TRUNCATE write\n",
    "    # disposition it replaces the table with the loaded data.\n",
    "    write_disposition=\"WRITE_TRUNCATE\",\n",
    ")\n",
    "\n",
    "job = client.load_table_from_dataframe(\n",
    "    dataframe, table_id, job_config=job_config\n",
    ")  # Make an API request.\n",
    "job.result()  # Wait for the job to complete.\n",
    "\n",
    "table = client.get_table(table_id)  # Make an API request.\n",
    "print(\n",
    "    \"Loaded {} rows and {} columns to {}\".format(\n",
    "        table.num_rows, len(table.schema), table_id\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query BQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f378a66a5c70410597234049835fae7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Query is running:   0%|          |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d56e4792ca5429f95ac57cbe67d3de4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Inventor</th>\n",
       "      <th>Location</th>\n",
       "      <th>PatentNumber</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Richard A. Lethin</td>\n",
       "      <td>New York, NY (US)</td>\n",
       "      <td>8,661,422 B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Allen K. Leung</td>\n",
       "      <td>New York, NY (US)</td>\n",
       "      <td>8,661,422 B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Benoit J. Meister</td>\n",
       "      <td>New York, NY (US)</td>\n",
       "      <td>8,661,422 B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nicolas T. Vasilache</td>\n",
       "      <td>New York, NY (US)</td>\n",
       "      <td>8,661,422 B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>David E. Wohlford</td>\n",
       "      <td>Portland, OR (US)</td>\n",
       "      <td>8,661,422 B2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Inventor             Location    PatentNumber\n",
       "0                     ---                  ---             ---\n",
       "1      Richard A. Lethin    New York, NY (US)    8,661,422 B2 \n",
       "2         Allen K. Leung    New York, NY (US)    8,661,422 B2 \n",
       "3      Benoit J. Meister    New York, NY (US)    8,661,422 B2 \n",
       "4   Nicolas T. Vasilache    New York, NY (US)    8,661,422 B2 \n",
       "5      David E. Wohlford    Portland, OR (US)    8,661,422 B2 "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "SELECT * FROM jsb-alto.entity_extract.patent_data_extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-12.m110",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-12:m110"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
